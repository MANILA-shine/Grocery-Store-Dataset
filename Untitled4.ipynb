{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnkAThvl9JfB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "F3CmVphH93AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "2GxEG7A597p-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv('/content/drive/MyDrive/GroceryDataset.csv')"
      ],
      "metadata": {
        "id": "e3wJHk2I-D7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "_x99wRBq-7ZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data.tail()"
      ],
      "metadata": {
        "id": "mIhDm0PwQ95A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The shape of the data is :\",data.shape)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "37LZFbb5-8u9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "ZuuWZMmx_RMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Sub Category'].unique()"
      ],
      "metadata": {
        "id": "XXvrwLRQ_AKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Sub Category'].nunique()"
      ],
      "metadata": {
        "id": "PabV4sbMR-Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are 19 different categories"
      ],
      "metadata": {
        "id": "-0QX_oO9SUCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[ 'Currency'].unique()"
      ],
      "metadata": {
        "id": "cjEMI6fs_E8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "srNh4mPh_m9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dtypes"
      ],
      "metadata": {
        "id": "unXyRz3FBi2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data.info()"
      ],
      "metadata": {
        "id": "axBeNGDAB_e_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(data['Currency']=='$').sum()"
      ],
      "metadata": {
        "id": "x3zV2jgeRKQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the currency used is only in Dollars \"$\""
      ],
      "metadata": {
        "id": "46A8xP8zRlR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values with mode for each column\n",
        "for column in data.columns:\n",
        "    data[column].fillna(data[column].mode()[0], inplace=True)"
      ],
      "metadata": {
        "id": "8WJuHWZ1Mg9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "rUJ3YdFBMaDt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n"
      ],
      "metadata": {
        "id": "p3pb4iziT9OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Product Categorization\n",
        "category_counts = data.groupby(['Sub Category', 'Title']).size().reset_index(name='Product Count')\n",
        "print(\"Product Categorization:\")\n",
        "print(category_counts)\n",
        "\n"
      ],
      "metadata": {
        "id": "FVlWT7vEt-pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Importance\n",
        "feature_corpus = ' '.join(data['Feature'].astype(str))\n",
        "feature_vectorizer = CountVectorizer()\n",
        "feature_matrix = feature_vectorizer.fit_transform([feature_corpus])\n",
        "feature_freq = pd.DataFrame(feature_matrix.toarray(), columns=feature_vectorizer.get_feature_names_out())\n",
        "print(\"\\nFeature Importance:\")\n",
        "print(feature_freq.transpose().sort_values(0, ascending=False))\n",
        "\n"
      ],
      "metadata": {
        "id": "nce2v9jGuEdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment Analysis\n",
        "data['Sentiment'] = data['Product Description'].apply(lambda x: TextBlob(str(x)).sentiment.polarity)\n",
        "print(\"\\nSentiment Analysis:\")\n",
        "print(data[['Title', 'Sentiment']])\n",
        "\n"
      ],
      "metadata": {
        "id": "A0N5EsyVuK4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Keyword Analysis\n",
        "def extract_keywords(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = word_tokenize(str(text))\n",
        "    keywords = [word.lower() for word in words if word.isalnum() and word.lower() not in stop_words]\n",
        "    return keywords\n",
        "\n"
      ],
      "metadata": {
        "id": "_GZZ4hSzuOT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Title Keywords'] = data['Title'].apply(extract_keywords)\n",
        "data['Feature Keywords'] = data['Feature'].apply(extract_keywords)\n",
        "data['Description Keywords'] = data['Product Description'].apply(extract_keywords)\n",
        "print(\"\\nKeyword Analysis:\")\n",
        "print(data[['Title Keywords', 'Feature Keywords', 'Description Keywords']])\n",
        "\n"
      ],
      "metadata": {
        "id": "WkusXH5buSNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Product Recommendations (using cosine similarity)\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(data['Feature'].astype(str))\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n"
      ],
      "metadata": {
        "id": "Xb5mEE8WuUs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_products(title, cosine_sim_matrix, data):\n",
        "    indices = pd.Series(data.index, index=data['Title']).drop_duplicates()\n",
        "    idx = indices[title]\n",
        "    sim_scores = list(enumerate(cosine_sim_matrix[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:6]\n",
        "    product_indices = [i[0] for i in sim_scores]\n",
        "    return data['Title'].iloc[product_indices]\n",
        "\n",
        "print(\"\\nProduct Recommendations:\")\n",
        "print(recommend_products('Cheetos Crunchy, Original, 2.1 oz, 64-count', cosine_sim, data))\n"
      ],
      "metadata": {
        "id": "5cfdPZJAuXDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# let's create a word cloud for Titles\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "title_corpus = ' '.join(data['Title'].astype(str))\n",
        "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(title_corpus)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.title('Word Cloud for Titles')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1Y8AJ_fguaLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oFQgQw6Wuhid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EDA: Histogram for Price\n",
        "import re\n",
        "\n",
        "# Remove non-numeric characters from 'Price'\n",
        "data['Price'] = data['Price'].replace('[^\\d.]', '', regex=True)\n",
        "\n",
        "# Convert 'Price' to float\n",
        "data['Price'] = pd.to_numeric(data['Price'], errors='coerce')\n",
        "\n",
        "# EDA: Histogram for Price\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data['Price'].dropna(), bins=30, kde=True, color='skyblue')\n",
        "plt.title('Distribution of Prices')\n",
        "plt.xlabel('Price')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xr87iEj_VNRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EDA: Bar chart for Sub Category counts\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.countplot(x='Sub Category', data=data, palette='viridis')\n",
        "plt.title('Distribution of Sub Categories')\n",
        "plt.xlabel('Sub Category')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bDZ52TnrVNOP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Analysis: Heatmap\n",
        "numerical_data = data[['Price', 'Rating']]  # Include other numerical columns as needed\n",
        "numerical_data = numerical_data.apply(pd.to_numeric, errors='coerce')  # Convert to numeric, handling errors\n",
        "correlation_matrix = numerical_data.corr()\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=.5)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "I_85N285VNKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing Sentiment Analysis Results: Boxplot\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x='Sub Category', y='Sentiment', data=data, palette='pastel')\n",
        "plt.title('Sentiment Analysis Across Sub Categories')\n",
        "plt.xlabel('Sub Category')\n",
        "plt.ylabel('Sentiment Score')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "w788GYSeVNHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Remove non-numeric characters from 'Price'\n",
        "data['Price'] = data['Price'].replace('[^\\d.]', '', regex=True)\n",
        "\n",
        "# Convert 'Price' to float\n",
        "data['Price'] = pd.to_numeric(data['Price'], errors='coerce')\n",
        "\n",
        "# EDA: Histogram for Price\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data['Price'].dropna(), bins=30, kde=True, color='skyblue')\n",
        "plt.title('Distribution of Prices')\n",
        "plt.xlabel('Price')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TU0FVXwrVNFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Remove non-numeric characters from 'Price'\n",
        "data['Price'] = data['Price'].replace('[^\\d.]', '', regex=True)\n",
        "\n",
        "# Convert 'Price' to float\n",
        "data['Price'] = pd.to_numeric(data['Price'], errors='coerce')\n",
        "\n",
        "# EDA: Histogram for Price\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data['Price'].dropna(), bins=30, kde=True, color='skyblue')\n",
        "plt.title('Distribution of Prices')\n",
        "plt.xlabel('Price')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "f-VCtx3bVNC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "PK67CUuOVNAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n"
      ],
      "metadata": {
        "id": "OkPmMJNJCtnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def label_encode_dataframe(data):\n",
        "    le = LabelEncoder()\n",
        "\n",
        "    for column in data.columns:\n",
        "        if data[column].dtype == 'object':\n",
        "            data[column] = le.fit_transform(data[column].astype(str))\n",
        "\n",
        "    return data\n",
        "\n",
        "# Assuming your DataFrame is named df\n",
        "data_encoded = label_encode_dataframe(data)\n",
        "\n",
        "# Display the DataFrame after label encoding\n",
        "print(data_encoded.head())"
      ],
      "metadata": {
        "id": "ZdrgIFunCHBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_encoded.info()"
      ],
      "metadata": {
        "id": "L6jrvh1oCpMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values in 'Price' with the mean\n",
        "data_encoded['Price'].fillna(data_encoded['Price'].mean(), inplace=True)\n",
        "\n",
        "# Verify that there are no more missing values\n",
        "data_encoded.info()"
      ],
      "metadata": {
        "id": "2bt75VYz0s3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_encoded=data_encoded.drop('Rating',axis=1)"
      ],
      "metadata": {
        "id": "gWoHWBopzYVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_unique_values(data):\n",
        "    for column in data.columns:\n",
        "        unique_values = data[column].unique()\n",
        "        print(f\"Column: {column}\")\n",
        "        print(\"Unique Values:\", unique_values)\n",
        "        print(\"\\n\")\n",
        "\n",
        "# Assuming your encoded DataFrame is named df_encoded\n",
        "print_unique_values(data_encoded)"
      ],
      "metadata": {
        "id": "5q4v6O0DDBab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_encoded.describe()"
      ],
      "metadata": {
        "id": "GyBPuUFPDEyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define columns for outlier detection\n",
        "numeric_columns = ['Price', 'Discount', 'Title', 'Currency', 'Feature', 'Product Description']\n"
      ],
      "metadata": {
        "id": "-I2uyBEPM59K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to detect outliers using IQR\n",
        "def detect_outliers(data, columns):\n",
        "    outliers = []\n",
        "    for column in columns:\n",
        "        Q1 = np.percentile(data[column], 25)\n",
        "        Q3 = np.percentile(data[column], 75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower_bound = Q1 - 1.5 * IQR\n",
        "        upper_bound = Q3 + 1.5 * IQR\n",
        "        column_outliers = data[(data[column] < lower_bound) | (data[column] > upper_bound)]\n",
        "        outliers.extend(column_outliers.index)\n",
        "    return list(set(outliers))\n",
        "\n",
        "# Detect outliers in numeric columns\n",
        "outliers_indices = detect_outliers(data_encoded, numeric_columns)"
      ],
      "metadata": {
        "id": "glz4PQFjM74k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display outliers\n",
        "outliers_data = data_encoded.loc[outliers_indices]\n",
        "print(\"Outliers:\")\n",
        "print(outliers_data)"
      ],
      "metadata": {
        "id": "mSHn6xZ-M71M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create box plots for numeric columns\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.boxplot(data=data_encoded[numeric_columns], palette='Set3')\n",
        "plt.title('Box Plots for Numeric Columns')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HFShG98HM7Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_encoded['Currency'].unique()"
      ],
      "metadata": {
        "id": "_7bzGs9sQzZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dollar_mask = data_encoded['Currency']\n",
        "sns.set_theme(palette=\"pastel\")\n",
        "sns.jointplot(data=data_encoded, x=\"Sub Category\",y=\"Title\",hue=dollar_mask)"
      ],
      "metadata": {
        "id": "bvReW5WDOIgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_encoded.corr()"
      ],
      "metadata": {
        "id": "ZiDWIEHDDVpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming your encoded DataFrame is named df_encoded\n",
        "correlation_matrix = data_encoded.corr()\n",
        "\n",
        "# Create a heatmap with a diverging colormap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True)\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WHe4cUgxDcV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "DsqH-1GTD2WB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display summary statistics for numerical columns\n",
        "print(\"\\nSummary Statistics:\")\n",
        "print(data_encoded.describe())"
      ],
      "metadata": {
        "id": "pK-9aeXpDspI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display missing values\n",
        "print(\"\\nMissing Values:\")\n",
        "print(data_encoded.isnull().sum())\n"
      ],
      "metadata": {
        "id": "WyKQX02DFeXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 15))\n",
        "data_encoded.hist(bins=20, color='skyblue', edgecolor='black', linewidth=1.2)\n",
        "plt.suptitle(\"Distribution of Numerical Columns\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hMR_AIFcFmKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize correlation heatmap\n",
        "correlation_matrix = data_encoded.corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"RdBu_r\", fmt=\".2f\", linewidths=.5)\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9blrsZijFpLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize categorical variables\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.countplot(x='Sub Category', data=data, palette='viridis')\n",
        "plt.title(\"Count of Products in Each Sub Category\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2DQfMNoiF2ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize categorical variables\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.countplot(x='Sub Category', data=data_encoded, palette='viridis')\n",
        "plt.title(\"Count of Products in Each Sub Category\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D_GTfk9HF8M-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(14, 8))\n",
        "sns.boxplot(x='Sub Category', y='Price', data=data_encoded, palette='Set3')\n",
        "plt.title(\"Price Distribution in Each Sub Category\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-KYTlFz6GDLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "sns.pairplot(data_encoded, diag_kind='kde', palette='viridis')\n",
        "plt.suptitle(\"Pair Plot of Numerical Columns\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mchBdpnaKgzz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='Discount', data=data_encoded, palette='pastel')\n",
        "plt.title(\"Distribution of Discounts\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "E2-2_zpxKt__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Example: Assuming 'Price' is the target variable\n",
        "X = data_encoded.drop(['Price'], axis=1)\n",
        "y = data_encoded['Price']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = RandomForestRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(f'Mean Squared Error: {mse}')\n"
      ],
      "metadata": {
        "id": "Jfq1S8QLLC_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize feature importance\n",
        "importances = model.feature_importances_\n",
        "features = X.columns\n",
        "indices = np.argsort(importances)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(range(len(indices)), importances[indices], align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Feature Importance')\n",
        "plt.title('Random Forest Feature Importance')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BFEbZMtvtSar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Importance Visualization\n",
        "feature_importances = model.feature_importances_\n",
        "features = X.columns\n",
        "\n"
      ],
      "metadata": {
        "id": "bUviBjoc1DWh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame to display feature importances\n",
        "feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': feature_importances})\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "DY8CDODY1NfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot feature importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='viridis')\n",
        "plt.title('Feature Importances')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "4Fvk4eY01yze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Tuning (example: hyperparameter tuning)\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Yu1P1N3b11Wu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameter grid to search\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n"
      ],
      "metadata": {
        "id": "yfwuMzRX14V1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create the grid search model\n",
        "grid_search = GridSearchCV(RandomForestRegressor(), param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "mRPkRGPE1586"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "print(f'Best Hyperparameters: {best_params}')\n",
        "\n"
      ],
      "metadata": {
        "id": "qc6PKRTV17x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrain the model with the best parameters\n",
        "best_model = RandomForestRegressor(**best_params)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n"
      ],
      "metadata": {
        "id": "AHkFGo1N2BgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with the tuned model\n",
        "tuned_predictions = best_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "FNCdnYxE2C1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the tuned model\n",
        "tuned_mse = mean_squared_error(y_test, tuned_predictions)\n",
        "print(f'Tuned Mean Squared Error: {tuned_mse}')"
      ],
      "metadata": {
        "id": "zBKOVKFQ2D_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrain the model with the best parameters\n",
        "best_model = RandomForestRegressor(max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50)\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions with the tuned model\n",
        "tuned_predictions = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the tuned model\n",
        "tuned_mse = mean_squared_error(y_test, tuned_predictions)\n",
        "print(f'Tuned Mean Squared Error: {tuned_mse}')\n"
      ],
      "metadata": {
        "id": "sEjkYHK02ES7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpretation:**"
      ],
      "metadata": {
        "id": "qECu_-Xp3c4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your target variable is 'Price'\n",
        "target_range = data_encoded['Price'].max() - data_encoded['Price'].min()\n",
        "\n",
        "print(f\"Target Variable Range: {target_range}\")\n",
        "print(f\"Tuned MSE in the context of the target variable's range: {tuned_mse / target_range}\")\n"
      ],
      "metadata": {
        "id": "wP2m1RAa3QIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison:**"
      ],
      "metadata": {
        "id": "rmG2oZBT3vGj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Original MSE: {mse}\")\n",
        "print(f\"Tuned MSE: {tuned_mse}\")\n",
        "\n",
        "# Assess whether tuning resulted in a meaningful improvement\n",
        "if tuned_mse < mse:\n",
        "    print(\"Tuning has resulted in a meaningful improvement.\")\n",
        "else:\n",
        "    print(\"Tuning has not led to a significant improvement.\")\n"
      ],
      "metadata": {
        "id": "GOPKvj4U3ZOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exploration:**"
      ],
      "metadata": {
        "id": "0JU7dQod33py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Linear Regression\n",
        "linear_model = LinearRegression()\n",
        "linear_model.fit(X_train, y_train)\n",
        "linear_predictions = linear_model.predict(X_test)\n",
        "linear_mse = mean_squared_error(y_test, linear_predictions)\n",
        "\n",
        "# Gradient Boosting\n",
        "gb_model = GradientBoostingRegressor()\n",
        "gb_model.fit(X_train, y_train)\n",
        "gb_predictions = gb_model.predict(X_test)\n",
        "gb_mse = mean_squared_error(y_test, gb_predictions)\n",
        "\n",
        "print(f\"Linear Regression MSE: {linear_mse}\")\n",
        "print(f\"Gradient Boosting MSE: {gb_mse}\")\n"
      ],
      "metadata": {
        "id": "ALdltJS83fyc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the relationship between a specific feature (e.g., 'Discount') and the target variable\n",
        "plt.scatter(X_test['Discount'], y_test, alpha=0.5)\n",
        "plt.title('Relationship between Discount and Price')\n",
        "plt.xlabel('Discount')\n",
        "plt.ylabel('Price')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jEi2lxLd3zuz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Create the grid search\n",
        "grid_search = GridSearchCV(RandomForestRegressor(), param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "best_predictions = best_model.predict(X_test)\n",
        "\n",
        "# Evaluate the tuned model\n",
        "best_mse = mean_squared_error(y_test, best_predictions)\n",
        "print(f\"Best Hyperparameter Tuning MSE: {best_mse}\")\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n"
      ],
      "metadata": {
        "id": "FjmB0mMx39N4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Creating a new feature by combining existing features\n",
        "data_encoded['New_Feature'] = data_encoded['Feature'] * data_encoded['Discount']\n",
        "\n",
        "# Update X and y accordingly\n",
        "X = data_encoded.drop(['Price'], axis=1)\n",
        "y = data_encoded['Price']\n"
      ],
      "metadata": {
        "id": "XA0TGa884J5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n"
      ],
      "metadata": {
        "id": "hp0wA9IM5MrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "# Create a SHAP explainer\n",
        "explainer = shap.Explainer(best_model)\n",
        "\n",
        "# Calculate SHAP values\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# Summary plot\n",
        "shap.summary_plot(shap_values, X_test)\n"
      ],
      "metadata": {
        "id": "ZecdPkWk4P48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Ensemble**"
      ],
      "metadata": {
        "id": "B47v1bqe4YwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import StackingRegressor\n",
        "from sklearn.linear_model import LassoCV\n",
        "\n",
        "# Define the base models\n",
        "base_models = [\n",
        "    ('random_forest', RandomForestRegressor(**best_params)),\n",
        "    ('linear_regression', LinearRegression())\n",
        "]\n",
        "\n",
        "# Define the meta-model\n",
        "meta_model = LassoCV()\n",
        "\n",
        "# Create the stacking model\n",
        "stacking_model = StackingRegressor(estimators=base_models, final_estimator=meta_model)\n",
        "stacking_model.fit(X_train, y_train)\n",
        "stacking_predictions = stacking_model.predict(X_test)\n",
        "\n",
        "# Evaluate the stacking model\n",
        "stacking_mse = mean_squared_error(y_test, stacking_predictions)\n",
        "print(f\"Stacking Model MSE: {stacking_mse}\")\n"
      ],
      "metadata": {
        "id": "riQ90-yK4SGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FBoXV6Lj4bPe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}